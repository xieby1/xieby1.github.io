<div style="font-size:3em; text-align:right">2019.10.21</div>
åœ¨åˆ˜å…ˆå–†çš„æ¨èä¸‹å»å¯»æ‰¾äº†LLVMä½œè€…chris lattnerçš„å­¦ä½è®ºæ–‡ï¼ˆthesisï¼‰ï¼Œå°±æ‰¾åˆ°äº†è¿™ç¯‡ï¼

# [LLVM: AN INFRASTRUCTURE FOR MULTI-STAGE OPTIMIZATION](../../../Essays/IR/2000.LLVM-AN_INFRASTRUCTURE_FOR_MULTI-STAGE_OPTIMIZATION.pdf)é˜…è¯»ç¬”è®°

## Abstract

çœ‹çš„å‡ºå†™è¿™ç¯‡è®ºæ–‡çš„åŠ¨æœºï¼Œæˆ–è€…è¯´å†™LLVMåŠ¨æœºæ˜¯æå‡ºæ–°çš„ç¼–è¯‘æ¡†æ¶æ¥è§£å†³ç¼–è¯‘æ—¶é—´è¿‡é•¿çš„é—®é¢˜ã€‚

LLVMçš„è®¾è®¡ç‰¹ç‚¹ï¼š

> It is a low-level representation, but with high-level type information.

## 1. Introduction

> This thesis describes the Low-Level Virtual Machine (LLVM), a compiler infrastructure which is well-suited for modern programming languages and architectures. LLVM is designed to achieve three critical goals:
> 1. Enable an aggressive multi-stage optimization strategy, providing maximum performance.
> 2. Serve as the host for leading edge research and development, providing a strong foundation for both current and future projects.
> 3. Operate transparently to the end-user (a developer), behaving identically to a standard system compiler (including realistic compilation times).

ç¬¬ä¸€ç‚¹ä¸çŸ¥é“æ˜¯ä¸æ˜¯å°±å˜æˆäº†ç°åœ¨çš„LLVMé‡Œçš„passäº†ã€‚ç¬¬äºŒæ¡çœ‹æ¥æ˜¯å¾ˆæœ‰é‡å¿ƒï¼Œä½†æ˜¯æˆ‘å¾ˆæƒ³çŸ¥é“ä»–å¦‚ä½•èƒ½åšåˆ°ï¼Œå¦‚ä½•ä¸ºå‰æ²¿ç ”ç©¶æœåŠ¡å‘¢ï¼Ÿ

> LLVM is designed to address one simple observation: human patience is limited.

ç®€å•çš„è¯´å°±æ˜¯â€œæ‡’ï¼Œæ¨åŠ¨ç§‘æŠ€è¿›æ­¥â€ï¼Œå“ˆå“ˆå“ˆå“ˆï¼<span style="font-size:1.5em;">ğŸ¤£ğŸ¤£ğŸ¤£</span>

---

#### 1.1.1 Traditional Approaches to Link-Time Interprocedural Optimization

æ–‡ç« æŠŠå½“æ—¶çš„Link-Time Interproceduralä¼˜åŒ–ï¼ˆå³åœ¨é“¾æ¥çš„æ—¶å€™ï¼ŒæŠŠå°½å¯èƒ½å¤šçš„ç¨‹åºèšé›†åœ¨ä¸€èµ·ï¼Œå¢å¤§åˆ†æçš„èŒƒå›´ï¼Œç„¶åè¿›è¡Œä¼˜åŒ–ï¼‰åˆ†æˆä¸¤ç±»ï¼Œ

1. åº•å±‚â€”â€”æœºå™¨ç çš„å±‚æ¬¡

   ä¼˜ç‚¹ï¼šä»»ä½•å‰ç«¯éƒ½å¯ä»¥ï¼ˆåªè¦èƒ½ç¼–æˆæ­£ç¡®çš„æœºå™¨ç ï¼‰ã€‚ç¼ºç‚¹ï¼šç¼ºä¹é«˜å±‚ä¿¡æ¯ç”¨ä»¥å¸®åŠ©ä¼˜åŒ–ã€‚

2. é«˜å±‚â€”â€”æŠ½è±¡è¯­æ³•æ ‘çš„å±‚æ¬¡å³IR

   ä¼˜ç‚¹ï¼šæœºå™¨ç çš„å±‚æ¬¡çš„ä¼˜åŒ–çš„ç¼ºç‚¹ã€‚ç¼ºç‚¹ï¼šä¸é€šç”¨ï¼ˆå¾ˆå¯èƒ½ä¸å¼€æ”¾ï¼‰ï¼Œä¸”éå¸¸è´¹æ—¶ã€‚

#### 1.1.2 Traditional Approaches to Run-Time Optimization
çœ‹æ–‡ç« çš„æ„æ€dynamic optimizationå’Œrun-time optimizationæ˜¯åŒä¹‰è¯ã€‚

1. High Level Language Virtual Machines

   Run-time optimizationå’ŒJust-In-Time compilationã€‚

   > These VMs often target very dynamic languages, such as SmallTalk [21], Self [44], Java [22], and C# [32], and use a machine-independent byte-code input which encodes these languages at a very high-level (effectively at the AST level).

2. Architecture Level Virtual Machines and Dynamic Translators

   å³åŠ¨æ€äºŒè¿›åˆ¶ç¿»è¯‘çš„å·¥ä½œã€‚

#### 1.1.3 Traditional Approaches to Compile-time Profile-Driven Optimization
5ä¸ªæ­¥éª¤ï¼Œ

1. > The first stage of compilation compiles the program, but inserts profiling instrumentation into
   > the program to cause it to gather some form of profile information at run-time.

2. > The second stage links these instrumented object files into an instrumented executable.

3. > The third stage of profile-driven optimization requires the developer of the application to run the generated executable through a series of test runs, which are used to generate the profile information for the application.

4. > Finally, the fourth and fifth stages recompile the program (often from source) and relink it, using the collected profile information to optimize the program.

ç¼ºç‚¹ï¼šprofilingä¸ä¸€å®šå‡†ç¡®ï¼Œä¸”éº»çƒ¦ã€‚

### 1.2 Multi-stage Optimization with LLVM
è¿™é‡Œè¯¦ç»†è¡¨è¾¾äº†LLVMçš„è®¾è®¡ç†å¿µï¼šé¢å¯¹ä¸Šè¿°3ç±»ä¼ ç»Ÿæ–¹æ³•çš„åŠ£åŠ¿ï¼ŒLLVMé€‰æ‹©çš„é“è·¯æ˜¯ç»™åº•å±‚è¡¨ç¤ºæä¾›ä¸Šå±‚çš„ç±»å‹ä¿¡æ¯ã€‚å› æ­¤éœ€è¦å®šä¹‰ä¸€ä¸ªè‡ªå·±çš„è™šæ‹ŸæŒ‡ä»¤é›†ã€‚åŸæ–‡å¦‚ä¸‹ï¼Œ

> The LLVM system architecture (described in Chapter 2) is designed to address these problems in traditional systems. Briefly, the static compilers in the LLVM system compile source code down to a low-level representation that includes high-level type information: The LLVM Virtual Instruction Set (described in Chapter 3). This allows the static compiler to perform substantial optimizations at compile time, while still communicating high-level information to the linker.

çœ‹åˆ°è¿™é‡Œï¼Œæ›´æƒ³å»çœ‹çœ‹JAVAç¬¬ä¸€ç‰ˆé‡Œbytecodeçš„è®¾è®¡äº†ï¼Œæƒ³çŸ¥é“ä¸ºä»€ä¹ˆJAVAçš„bytecodeï¼ˆåæ­£ä¸æ˜¯bytecodeçš„åŸå› ï¼Œè¿™ç¯‡æ–‡ç« é‡Œæœ‰æ—¶ä¹ŸæŠŠLLVM IRå«åšLLVM bytecodeï¼ˆåº”è¯¥æ˜¯LLVMçš„å­˜å‚¨å½¢å¼ï¼‰è€Œæ˜¯bytecodeçš„è®¾è®¡ï¼‰ä¼šæ˜¯é«˜å±‚æ¬¡çš„IRã€‚**æ³¨**ï¼šä¸ºä»€ä¹ˆè¯´â€œæ›´â€ï¼Œå› ä¸ºä¹‹å‰åœ¨çœ‹ [LLVM: A Compilation Framework for Lifelong Program Analysis & Transformation](../../../Essays/IR/2004.LLVM-A_Compilation_Framework_for_Lifelong_Program_Analysis_Transformation.pdf) æ—¶ä¹Ÿæåˆ°äº†JAVAè™šæ‹Ÿæœºï¼Œè¯¦ç»†è§è¿™ç¯‡æ–‡ç« çš„[é˜…è¯»ç¬”è®°](2004.LLVM-A_Compilation_Framework_for_Lifelong_Program_Analysis_Transformationé˜…è¯»ç¬”è®°.md)ã€‚

ä¹‹åè¿˜æåˆ°LLVMé™æ€é“¾æ¥çš„è®¾è®¡å’Œè¿è¡Œæ—¶ä¼˜åŒ–çš„è®¾è®¡ï¼Œæš‚æ—¶ä¸åœ¨æˆ‘è¿™æ¬¡ç ”ç©¶IRçš„èŒƒå›´å†…ï¼Œå°±ä¸èµ˜è¿°äº†ã€‚

### 1.3 Research Contributions of this Thesis
ä¹‹å‰çœ‹æ–‡ç« å¥½åƒæ²¡æœ‰çœ‹åˆ°è¿‡ç±»ä¼¼çš„æŠŠè‡ªå·±çš„æ–‡ç« çš„è´¡çŒ®åˆ—ä¸¾å‡ºæ¥çš„ç« èŠ‚ã€‚æŒºæœ‰æ„æ€çš„ï¼Œå€¼å¾—å­¦ä¹ å­¦ä¹ è¿™ä¸ªç« èŠ‚ã€‚è¿™ä¸ªç« èŠ‚èƒ½å¤Ÿè®©ä½œè€…å†™æ–‡ç« æ—¶æ€è·¯æ¸…æ™°ï¼Œä¹Ÿèƒ½è®©è¯»è€…å¯¹ä½œè€…çš„å·¥ä½œä¸€ç›®äº†ç„¶ã€‚è¿™ç¯‡æ–‡ç« æ•´ä½“çš„å†™ä½œé£æ ¼ä¹Ÿå€¼å¾—å­¦ä¹ ã€‚ï¼ˆç›¸æ¯”åä¸ºçš„[MAPLE IR](MapleIRDesign.md)ï¼ˆ**æ³¨**ï¼šæ¥è‡ªOpenArkCompileré¡¹ç›®çš„æ–‡æ¡£ï¼Œå³åä¸ºçš„æ–¹èˆŸç¼–è¯‘å™¨çš„æ–‡æ¡£ï¼‰ï¼Œè¿™ç¯‡æ–‡ç« çš„å¯è¯»æ€§é«˜å¤šäº†ï¼MAPLE IRé‡Œä¸çŸ¥é“æ˜¯ä¸æ˜¯ç”¨çš„ç¿»è¯‘è½¯ä»¶ç¿»è¯‘çš„ï¼Œä¸€å †å¥‡æ€ªçš„è¯ï¼Œä¸€å †å¥‡æ€ªçš„è¡¨è¾¾ï¼Œç„¶åå°±ä¸æƒ³å»çœ‹æ•´ä½“çš„è¡Œæ–‡é€»è¾‘äº†ï¼‰

è¿™é‡Œçš„ç¬¬3ç‚¹ï¼Œæåˆ°äº†LLVMæˆåŠŸç”¨äºIllinoiså¤§å­¦çš„advanced compilers classï¼Œæ–‡ç« è¿˜æåˆ°ï¼Œ

> Students tend to be much less forgiving than researchers about a poor design, lack of documentation, buggy implementation, or poor extensibility, so this demonstrates a great deal of maturity.

åœ¨å’Œå­¦ç”Ÿçš„ç£¨åˆä¸­ï¼Œè®©LLVMæœ‰å¾ˆå¥½çš„è®¾è®¡ã€ä¸°å¯Œçš„æ–‡æ¡£å’Œå¼€æ”¾çš„æ¥å£ã€‚æˆ‘æƒ³æ­£æ˜¯å¦‚æ­¤ï¼ŒLLVMæ‰èƒ½èµ°å‡ºæ ¡å›­ï¼Œå¸å¼•ä¼—å¤šçš„ç ”ç©¶è€…å’Œå¼€å‘è€…ä¸æ–­åŠ å…¥LLVMçš„å¼€å‘ä¸­ï¼Œè®©LLVMä¸æ–­å£®å¤§ï¼Œä»¥è‡³äºå˜ä¸ºç›®å‰ä¸¾ä¸–æ–‡æ˜çš„ç¼–è¯‘ç³»ç»Ÿå§ã€‚æˆ‘è§‰å€¼å¾—å­¦ä¹ çš„åœ°æ–¹å¾ˆå¤šå¾ˆå¤šï¼Œç­‰è¿™å‘¨ä¸‰çš„æŠ¥å‘Šç»“æŸåï¼Œæœ‰æ—¶é—´å†æ¥å¥½å¥½ç ”è¯»ç ”è¯»è¢«æˆ‘è·³è¿‡çš„å’ŒIRä¸å¤ªæœ‰å…³ç³»çš„éƒ¨åˆ†å§ã€‚

<div style="font-size:3em; text-align:right">2019.10.22</div>
## 2. LLVM System Architecture

> The key points of the high-level LLVM system design is that the LLVM virtual instruction set (described in more detail in Chapter 3) is used the communicate between the different tools, and the tools fit into a standard development framework. Operating on a common representation allows the transformations to be shared between the different components of the system.

### 2.2 Compile Time: Front-end & Static Optimizer

> The primary job of the language front-end is to translate from the source language to the LLVM virtual instruction set, but it can also perform language-specific optimizations as well.

è¿™é‡Œæåˆ°åªé€‚ç”¨äºç‰¹å®šè¯­è¨€çš„ä¼˜åŒ–ï¼Œå¯ä»¥äº¤ç»™å‰ç«¯å®Œæˆã€‚ï¼ˆè¿™é‡Œçš„å‰ç«¯æ˜¯æŒ‡æŠŠé«˜çº§è¯­è¨€ç¿»è¯‘æˆLLVM bytecodeçš„éƒ¨åˆ†ï¼‰

---

> Unlike high-level virtual machines, the LLVM type system does not specify an object model, memory management system, or specific exception semantics that each language must use. Instead, LLVM only directly supports the lowest-level type constructors, such as pointers, structures, and arrays, relying on the source language to map the high-level type system to the low-level one. In this way, LLVM is language independent in the same way a microprocessor is: all high-level features are mapped down to simpler constructs.

è¿™é‡Œæåˆ°äº†LLVM IRä½å±‚æ¬¡çš„ç‰¹ç‚¹ã€‚

---

ç¬¬2ç« åé¢çš„å†…å®¹éƒ½è·³è¿‡äº†ã€‚

## 3. LLVM Virtual Instruction Set

### 3.1 Overview of the LLVM Virtual Instruction Set
> The virtual registers are in Static Single Assignment (SSA) form [^15], a widely used representation for compiler optimization, as explained in Section 3.2.1.

è¿™é‡Œæåˆ°äº†æˆ‘æƒ³äº†è§£çš„SSAï¼Œå¹¶æ¨èäº†ä¸€ç‰‡ç›¸å…³è®ºæ–‡ã€‚

[^15]: Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. [Efficiently computing static single assignment form and the control dependence graph](../../../Essays/IR/1991.Efficiently_Computing_Static_Single_Assignment_Form_and_the_Control_Dependence_Graph.pdf)ï¼ˆæ³¨ï¼šLLVM A Compilation Framework for Lifelong Program Analysis & Transformationè¿™ç¯‡æ–‡ç« é‡Œä¹Ÿæœ‰æåˆ°ã€‚ï¼‰. ACM Transactions on Programming Languages and Systems, pages 13(4):451â€“490, October 1991.

> Note that LLVM is a virtual instruction set: it does not define runtime and operating system functions such as I/O, memory management (in particular, garbage collection), signals, and many others. These features are defined by runtime libraries and APIs that programs link against. On the other hand, the LLVM virtual instruction set is a *first class language* which has a textual, binary, and in-memory representation. The implications of this decision are discussed in Section 3.6.

LLVM IRä¸åŒ…æ‹¬çš„å†…å®¹å¦‚ä¸Šã€‚

<span style="color:red;">ğŸ¤”ä»€ä¹ˆæ˜¯first class language?</span>çœ‹æ¥å°±ä»…ä»…æ˜¯â€œä¸€æµâ€çš„æ„æ€å’¯ï¼Ÿ

---

### 3.2 Three-Address Code
#### 3.2.1 Static Single Assignment Form
> A program is said to be in SSA form if each of its variables is defined exactly once, and each use of a variable is dominated by that variableâ€™s definition. SSA form greatly simplifies many dataflow optimizations because only a single definition can reach a particular use of a value, and finding that definition is trivial. It also enables fast flow-insensitive algorithms to achieve many of the benefits of flow-sensitive algorithms without expensive dataflow analysis (sometimes referred to as the sparseness property).

SSAçš„å…³é”®æ˜¯æ¯ä¸ªå˜é‡åªå®šä¹‰ä¸€æ¬¡ï¼ˆå’Œé«˜çº§è¯­è¨€çš„å±€éƒ¨å˜é‡çš„æ¦‚å¿µç›¸åï¼Œå±€éƒ¨å˜é‡åªéœ€ä¿è¯åœ¨ä¸€ä¸ªåŒºåŸŸé‡Œåªæœ‰æ¯ä¸ªå˜é‡åªæœ‰ä¸€ä¸ªæœ‰æ•ˆçš„å®šä¹‰ï¼‰ï¼ˆè¿™å¤§æ¦‚å°±æ˜¯LLVMéœ€è¦æ— é™ä¸ªå¯„å­˜å™¨çš„ç†ç”±äº†ï¼‰ã€‚äºæ˜¯åˆæ–¹ä¾¿åˆ†ææ•°æ®æµçš„ä¼˜åŠ¿ã€‚

phièŠ‚ç‚¹è§£å†³èµ‹å€¼è¯­å¥å¯èƒ½æœ‰å¤šä¸ªæ¥æºã€‚

### 3.3 High-level Type Information

åˆ—ä¸¾äº†æ‰€æœ‰ç±»å‹ï¼Œ

> primitive types (void, bool, signed and unsigned integers from 8 to 64 bits, floating-point values in single and double precision, and opaque) and constructive types (pointers, arrays, structures, and functions).

ä¸¾ä¾‹å­å¦‚ä½•æŠŠé«˜ä¸¾è¯­è¨€çš„ç»“æ„æ˜ å°„åˆ°è¿™äº›ç±»å‹ä¸Šå»ã€‚

#### 3.3.1 Type-safe Pointer Arithmetic with the getelementptr Instruction
### 3.4 Explicit Memory Allocation and Unified Memory Model

### 3.5 Function Calls and Exception Handling

### 3.6 Plain-text, Bytecode, and In-memory Representations

**æ³¨**ï¼šæ„Ÿè§‰3.3~3.6çš„å†…å®¹[LLVM Assembly Language Reference Manual.html](LLVM Assembly Language Reference Manual.html) å’Œ[2004.LLVM-A_Compilation_Framework_for_Lifelong_Program_Analysis_Transformation.pdf](../../../Essays/IR/2004.LLVM-A_Compilation_Framework_for_Lifelong_Program_Analysis_Transformation.pdf) å·®ä¸å¤šï¼Œä¸è¿‡è¿™ç¯‡æ–‡ç« çš„å†…å®¹æ›´è¯¦ç»†ã€‚ä¹‹åæœ‰éœ€è¦å†æ¥è¿™ç¯‡æ–‡ç« æŸ¥è¯¢å§ã€‚

