<div style="text-align:right; font-size:3em;">2021.12.06</div>

总的来说，当时的Xen的优势是不需要借助硬件虚拟化，就可以实现高效的系统级虚拟化。但是缺陷是需要对操作系统进行修改。与Xen相对比的vmware esx，不需要修改操作系统，但是要模拟执行特权指令，所以效率不高。

现在看来Xen和esx都在相互借鉴。Xen支持硬件虚拟化。以esx为代表的运行原生操作系统的vmm，也会提供专用驱动给用户，安装在操作系统中，以提升用户体验。

从现在的我的角度看，我最大的收获是测试方法。文章找了多个类似功能的产品，使用的各类测试方法，使用的各类benchmark。尽可能完整的测试整改系统的性能。反倒是实现细节，因为没有详细做过虚拟化的工作，所以看不太明白。这些实现细节在需要的时候再配合源码，认真去看文章更好。

下面是阅读过程中的记录：

## Intro

文章提到了vmware esx，第一次听到vmware的这个产品。有点感兴趣。查阅了一下是vmare的虚拟机管理器。在x86提出硬件虚拟化支持之前，采用类似二进制翻译的技术。

page color 和我知道的page color一样吗

Denali project第一次听说这个项目。并不是为了运行通用的程序。以后有闲暇时间可以去看看这个技术。

## Virt. Interface

Xen需要给guest模拟的接口被分成3个部分，都是硬件层次的资源，如下

### H.W. Resources

#### Mem

X86没有软件管理的TLB所以要介入页表比较麻烦。当然现在看来市场主流——ARM、X86都没有软件TLB。

为了减少xen和guest来回切换的代价，xen在驻留在每个guest每个进程的顶端64MB。

#### CPU

x86有4个特权等级可用。Xen运行在ring0, guest操作系统在ring1, guest应用在ring3。

处理int 0x80的方法：https://wiki.xenproject.org/wiki/Xen_FAQ_Design_and_in_Depth。

应该是根据触发int 0x80的上下文，由Xen把in 0x80转发给对应的虚拟机。

文章提到由对fast系统调用做优化，不需要进入ring0。这个技术未来有空再详细看吧？

仅仅只有page fault涉及ring0特权指令吗？

> Unfortunately it is not
> possible to apply the same technique to the page fault handler be-
> cause only code executing in ring 0 can read the faulting address
> from register CR2; page faults must therefore always be delivered
> via Xen so that this register value can be saved for access in ring 1.

#### Device

### Cost of Porting

改动guest操作系统的代码量不算大，linux约3000行

### WindowsProject Control and Management

> System call interrupt based [i386]: During booting process, linux kernel of a domU register's its IDT with Xen Hypervisor via HYPERVISOR_set_trap_table(trap_table); [arch/i386/kernel/traps-xen.c]. Xen maintains two IDT's, one global IDT (its own) and other per domain IDT. Xen uses global IDT to register the entire trap handler except for system call handler (int 0x80). When a VM gets scheduled, its system call handler (from per domain IDT table) is registered with the processor. Hence when a domain/VM executes a system call, its own handler is executed.

## Detailed Design

### Control Transfer: Hypercalls & Events

Hypercall: Guest => Xen 同步

Events: Xen => Guest 异步

### Data Transfer: IO Rings

描述的不清楚。全局有几个Rings？谁申请，谁分配？如何区分不同domain？

### Subsystem Virt.

#### CPU Sched.

#### Timers

#### Virt. Addr. Tran.

Read only page table

Page table update through hypercall

#### Phys. Mem.

#### Network

#### Disk

### Building a New Domain

## Evaluation

使用了很多benchmark，很有参考价值，总结如下：

### Benchmarks

* SPEC INT2000: Computation intensive
  * processor
  * memory system
  * compiler quality
* Linux build time: 7% in system:
  * file IO
  * scheduling
  * memory management
* Open Source Database Benchmark
  * socket communication
* dbench
  * file system operations
* SPEC WEB99: Web server: Page requests
  * 30% dyn. content generation
  * 16% HTTP POST
  * 0.5% CGI script
  * file system, network.

### OS Benchmarks

* lmbench:操作系统各个部件的小测试
* ttcp：网络传输

### Concurrent Virt. Machine

* SMP多进程vsXen多domain单线程

### Perf. Isolation

其他domain的异常行为是否影响正常domain性能，微小。

### Scalability

## 相关工作

由很多可以参考的工作。


