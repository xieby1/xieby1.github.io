% Doc Thoughts
% 🤓xieby1
% 2022.5.?

# Motivation

<!-- Number of slides is huge, so toc is huge -->
<style>
[role="doc-toc"] {zoom: 60%;}
[role="doc-toc"] > ul {column-width: 400px;}
</style>

* HM (Homogeneous)
* Single-ISA HT (Heterogeneous)
* **Multi-ISA HT**

::: {style="zoom: 60%;"}
📄Survey: 2015. *Heterogeneous Multi-core Architectures*,
Tulika Mitra, jip, 15
:::

## Multi-ISA HT

😎Ashish Venkat

::: {style="zoom: 90%;"}
| Y    | C/J    | Cit | Name                                                                        |
|------|:------:|:---:|-----------------------------------------------------------------------------|
| 2012 | asplos | 95  | Execution migration in a heterogeneous-ISA chip multiprocessor              |
| 2014 | isca   | 112 | Harnessing ISA diversity: Design of a heterogeneous-ISA chip multiprocessor |
| 2016 | asplos | 26  | HIPStR: Heterogeneous-ISA Program State Relocation                          |
| 2018 | doc    | 5   | **Breaking the ISA Barrier in Modern Computing**                            |
| 2019 | hpca   | 17  | Composite-ISA Cores: Enabling Multi-ISA Heterogeneity Using a Single ISA    |
:::

# Process Migration

<h2>Execution Migration in a Heterogeneous-ISA Chip Multiprocessor</h2>

Matthew DeVuyst, **Ashish Venkat**, Dean M. Tullsen

University of California, San Diego

2012 asplos 95

## Motivation

Single-ISA HT v.s. Single-ISA HM (Homogeneous)

* performance
* energy efficiency

Multi-ISA HT v.s. Single-ISA HT

* process migration

HT Cores v.s. HT Machines

* shared memory, copy less

## Overview

::: {.container}
:::: {.col style="zoom: 70%;"}
<h3>Mechanism</h3>

* Fat executables
* Equivalence point
  * memory state is equivalent
  * constraint to function call
* Binary translate
* State transform
::::
:::: {.col style="zoom: 133%;"}
![](./pictures/process_migration.svg)
::::
:::

## State Transformation

::: {.container}
:::: {.col}
<h3>Compile Time</h3>

Memory Image Consistency

::::: {style="zoom: 70%;"}
* Global Data
* Code Section
  * same function address
  * (call addr may not same)
* Heap
  * same implement `malloc`
* Stack
  * ABI, ARM & MIPS (RISC)
    * padding
:::::

::::
:::: {.col}
<h3>Run Time</h3>

Stack Transformation

::::: {style="zoom: 70%;"}
* depends on compilation info
* local variable locations
  * register
  * fixed stack slot
  * register spilled on stack
:::::

::::
:::

## Result & Analysis

* Runtime Compromise
  * On average suffers by 3.1% in ARM, 1.6% in MIPS
* Migration Cost
* Migration Points
* Binary Translation Cost

## Migration Cost

(Without Binary Translation)

<img src="./pictures/2012.f2.migration_cost.svg" style="zoom: 200%;">

On average

* 272ms ARM => MIPS
* 344ms MIPS => ARM

<!-- <img src="./pictures/2012.f3.perf_freq_no_bt_st.svg" style="zoom: 120%;"> -->

<!-- Perf. (no BT&ST) vs freq. -->

<!-- * Binary Translation -->
<!-- * State Transformation -->

## Migration Points

<img src="./pictures/2012.f4.time_to_next_call.svg" style="zoom: 120%;">

dummy calls added to

* outermost loops
  * -1.4% ARM, -4.7% MIPS
* second-innermost loops
  * -2.3% ARM, 5.4% MIPS

## Binary Translation Cost

::: {.container}
:::: {.col}
<img src="./pictures/2012.f10.migration_cost_bt_st.svg" style="zoom: 120%;">

* BT: Inst Expansion Ratio 1~3.5
::::
:::: {.col}
<img src="./pictures/2012.f11.perf_freq.svg" style="zoom: 120%;">

Perf. vs migration freq.
::::
:::

## Summary

* need to transform stack & regs
* no need to transform pointers
* runtime compromise (w/o migration)
  * -1.6% MIPS, -3.1% ARM
* state transformation
  * 272us ARM=>MIPS, 344us MIPS=>ARM
* binary translation
  * 2.75ms ARM=>MIPS, 7.24ms MIPS=ARM
* migrate per O(100ms) perf loss < 5%

# ISAs Explore

<h2>Harnessing ISA Diversity: Design of a Heterogeneous-ISA Chip Multiprocessor</h2>

**Ashish Venkat**, Dean M. Tullsen

University of California, San Diego

2014 isca 112

## uArch Design Space

::: {style="zoom: 60%;"}
| Design Parameter                 | Design Choices                         |
|----------------------------------|----------------------------------------|
| ISA                              | Thumb, Alpha, x86-64                   |
| Execution Semantics              | In-order, Out-of-order                 |
| Issue width                      | 1, 2, 4                                |
| Branch Predictor                 | local, tournament                      |
| Reorder Buffer Size              | 64, 128 entries                        |
| Architectural Register File      | ISA-specific                           |
| Physical Register File (Integer) | 96, 160                                |
| Physical Register File (FP/SIMD) | 64, 96                                 |
| Integer ALUs                     | 1, 3, 6                                |
| Integer Multiply/Divide Units    | 1, 2                                   |
| Floating-point ALUs              | 1, 2, 4                                |
| FP Multiply/Divide Units         | 1, 2                                   |
| SIMD Units                       | 1, 2, 4                                |
| Load/Store Queue Sizes           | 16, 32 entries                         |
| Instruction Cache                | 32KB 4-way, 64KB 4-way                 |
| Private Data Cache               | 32KB 4-way, 64KB 4-way                 |
| Shared Last Level (L2) Cache     | 4-banked 4MB 4-way, 4-banked 8MB 8-way |
:::

## uArch Design Space (Pruned)

~750k combinations

↓

Prune correlations

↓

600 combinations

::: {style="zoom: 60%;"}
| Design Parameter             | Design Choices                                                         |
|------------------------------|------------------------------------------------------------------------|
| ISA                          | Thumb, Alpha, x86-64                                                   |
| Execution Semantics          | In-order, Out-of-order                                                 |
| Branch Predictor             | local, tournament                                                      |
| Reorder Buffer-Register File | 64-96-64, 128-160-96 entries                                           |
| Issue Width-Functional Units | 1-1-1-1-1-1, 1-3-2-2-2-2, 2-3-2-2-2-2, 4-3-2-2-2-2, 4-6-2-4-2-4        |
| Load/Store Queue Sizes       | 16, 32 entries                                                         |
| Cache Hierarchy              | 32K/4-32K/4-4M/4, 32K/4-32K/4-8M/8, 64K/4-64K/4-4M/4, 64K/4-64K/4-8M/8 |
:::

## Result & Analysis

* (All-Tests) ISA Affinity
    * All tests preferred uArch/ISA
* Performance and Energy Efficiency
* (Particular-Test) ISA Affinity
    * Particular test preferred ISAs
* Migration Cost

## (All-Tests) ISA Affinity

uArch Design Space Result

::: {.container}
:::: {.col}
* X: uArch parameters
* Y: frequency of occurrence
* Data: **best designs** from all experiments
::::
:::: {.col}
![](./pictures/2014.f8.design_space_exploration.svg)
::::
:::

## Performance and Energy Efficiency

::: {.container style="zoom: 70%;"}
:::: {.col}
Test targets

* Homogeneous
* Single-ISA
* 🎉**Heterogeneous-ISA**
::::
:::: {.col}
Tests

| x          | y       | workload      |
|------------|---------|---------------|
| Peak Power | Speedup | Multi Thread  |
| Area       | Speedup | Multi Thread  |
| Peak Power | EDP     | Multi Thread  |
| Area       | EDP     | Multi Thread  |
| Peak Power | Speedup | Single Thread |
| Area       | Speedup | Single Thread |
| Peak Power | EDP     | Single Thread |
| Area       | EDP     | Single Thread |
::::
:::

## ISA Affinity

::: {.container}
:::: {.col style="zoom: 75%;"}
* 4 columns : 4 optimizations
  * Single-thread performance
  * Multi-program performance
  * Single-thread EDP (Power)
  * Multi-program EDP (Power)
::::
:::: {.col}
![](./pictures/2014.f9.isa_affinity.svg)
::::
:::

## Migration Cost

::: {.container}
:::: {.col}
<img src="./pictures/2014.f10.migration_dynamic_insts_num.svg" style="zoom: 140%;">

Distance to next equivalence
::::
:::: {.col}
<img src="./pictures/2014.f11.avg_migration_time.svg" style="zoom: 140%;">

Average time: 4ms
::::
:::: {.col}
<img src="./pictures/2014.f12.migration_bt_percent.svg" style="zoom: 140%;">

BT percentage
::::
:::

## Summary

* HM => single-ISA HT => HT ISA
* uArch design space exploration
* +20.8% perf. -23% energy than single-ISA HT
* avg migration time: 4ms, bt high%

# Mitigate ROP Attack

::: {style="zoom: 60%;"}
ROP (Return-Oriented Programming)
:::

<h2>HIPStR – Heterogeneous-ISA Program State Relocation</h2>

**Ashish Venkat**, Sriskanda Shamasunder, Dean M. Tullsen, Hovav Shacham

University of California, San Diego

2016 asplos 26

# Composite ISA

<h2>Composite-ISA Cores: Enabling Multi-ISA Heterogeneity Using a Single ISA</h2>

::: {.container}
:::: {.col}
**Ashish Venkat**

University of Virginia
::::
:::: {.col}
Harsha Basavaraj Dean M. Tullsen

University of California, San Diego
::::
:::

2019 hpca 17

## Motivation

<h3>HT ISA problems</h3>

* licensing
* verification costs & barriers
* process migration fat binaries
* binary translation costs
* state transformation costs

<h3>Solution</h3>

* Composite ISA
    * Superset ISA resembles x86
    * Subset ISA HT

## ISA Design Space

<!-- | Design Parameter   | Design Choices                                    | -->
<!-- |--------------------|---------------------------------------------------| -->
<!-- | Register Depth     | 8, 16, 32, 64                                     | -->
<!-- | Register Width     | 32, 64                                            | -->
<!-- | Opcode & Addr Mode | RISC(microx86), CISC                              | -->
<!-- | Predication        | partial (x86), full with gpr (this), full with cc | -->
<!-- | Data-Parallel      | with SSE2, without SSE2                           | -->

::: {.container}
:::: {.col}
::::
:::: {.col style="zoom: 100%;"}
| ISA Parameter                          | Options                                                                                                       |
|----------------------------------------|---------------------------------------------------------------------------------------------------------------|
| Register depth                         | 8, 16, 32, 64 registers                                                                                       |
| Register width                         | 32-bit, 64-bit registers                                                                                      |
| Instruction/Addressing mode complexity | 1:1 macroop-microop encoding (load-store x86 micro-op ISA), 1:n macroop-microop encoding (fully CISC x86 ISA) |
| Predication Support                    | Full Predication like IA-64/Hexagon vs Partial (cmov) Predication                                             |
| Data Parallelism                       | Scalar vs Vector (SIMD) execution                                                                             |
::::
:::
<img src="./pictures/2019.f1.uarch_design_sapce.svg" style="zoom: 140%;">

## uArch Design Space

::: {style="zoom: 60%;"}
| Microarchitectural Parameter          | Options                                    |
|---------------------------------------|--------------------------------------------|
| Execution Semantics                   | Inorder vs Out-Of-Order designs            |
| Fetch/Issue Width                     | 1, 2, 4                                    |
| Decoder Configurations                | 1-3 1:1 decoders, 1 1:4 decoder, MSROM     |
| Micro-op Optimizations                | Micro-op Cache, Micro-op Fusion            |
| Instruction Queue Sizes               | 32, 64                                     |
| Reorder Buffer Sizes                  | 64, 128                                    |
| Physical Register File Configurations | (96 INT, 64 FP/SIMD), (64 INT, 96 FP/SIMD) |
| Branch Predictors                     | 2-level local, gshare, tournament          |
| Integer ALUs                          | 1, 3, 6                                    |
| FP/SIMD ALUs                          | 1, 2, 4                                    |
| Load/Store Queue Sizes                | 16, 32                                     |
| Instruction Cache                     | 32KB 4-way, 64KB 4-way                     |
| Private Data Cache                    | 32KB 4-way, 64KB 4-way                     |
| Shared Last Level (L2) Cache          | 4-banked 4MB 4-way, 4-banked 8MB 8-way     |
:::

## Results & Analysis

* (All-Tests) Feature Affinity
    * All tests preferred feature
* Performance and Energy Efficiency
* *Feature Sensitivity Analysis*
    * by removing some feature diversity
* *(Particular-Test) Feature Affinity*
    * Particular test preferred features
* Migration Cost

::: {style="zoom: 70%;"}
by 2 petaflop XSEDE Comet cluster at the San Diego Supercomputing Center
:::

## (All-Tests) Feature Affinity

Feature Space Explore Results

::: {.container}
:::: {.col}
<img src="./pictures/2019.t3.perf_space_explore.svg" style="zoom: 120%;">

::::: {style="zoom: 80%;"}
opt for multi-thread perfermance
:::::
::::
:::: {.col}
<img src="./pictures/2019.t4.energy_space_explore.svg" style="zoom: 120%;">

::::: {style="zoom: 80%;"}
opt for multi-thread energy efficiency
:::::
::::
:::

## Performance and Energy Efficiency

::: {.container style="zoom: 70%;"}
:::: {.col}
Test targets

* Homogeneous (x86-64)
* Single-ISA Heterogeneous (x86-64)
* Composite-ISA fixed feat. (x86-64 + x86ized Thumb + x86ized Alpha)
* Heterogeneous ISA (x86-64 + Thumb + Alpha)
* 🎉**Composite-ISA full feat. (x86-64 + Full Feat. Diversity)**
::::
:::: {.col}
Tests

| x          | y       | workload      |
|------------|---------|---------------|
| Peak Power | Speedup | Multi Thread  |
| Area       | Speedup | Multi Thread  |
| Peak Power | EDP     | Multi Thread  |
| Area       | EDP     | Multi Thread  |
| Peak Power | Speedup | Single Thread |
| Area       | Speedup | Single Thread |
| Peak Power | EDP     | Single Thread |
| Area       | EDP     | Single Thread |
::::
:::

## Migration Cost

::: {.container}
:::: {.col}
<h3>Specific feature downgradation</h3>

<img src="./pictures/2019.f14.feat_downgrade_cost.svg" style="zoom: 140%;">
::::
:::: {.col}
<h3>Overall feature downgradation</h3>

average 0.42%, max 0.75%

* 1863 migrations
    * 125 64-bit => 32-bit
    * 171 64 regs => 32 regs
    * 177 64 regs => 16 regs
    * 8 x86 => microx86
::::
:::

## Summary

Composite ISA

* no licensing problem
* no fat binary
* no state transformation
* +19% perf., -30% energy than single-ISA HT
* match or outperform HT-ISA
* Migration Cost: avg 0.42%, max 0.75%

## Doubt

<img src="./pictures/2019.f4.x86_fetch_decode.svg" style="zoom: 150%;">

> Our
> implementations of the micro-op cache and fusion are consistent
> with guidelines mentioned in the Intel Architecture Optimization
> Manual [112].

::: {style="zoom: 70%;"}
[112] Intel R 64 and IA-32 Architectures Optimization Reference Manual.
:::

# ISA HT Summary

<h2>Pros</h2>

* a new arch design: ISA HT
* higher perfermance, less energy

<h2>Cons</h2>

* (intrinsic) need re-compilation
* not implement in OS

# My Ideas

<h2>Pros</h2>

* a new arch design: ISA HT
* higher perfermance, less energy

::: {.container}
:::: {.col}
<h2>Cons</h2>

* (intrinsic) need re-compilation
* not implement in OS (kernel)
::::
:::: {.col}
<h2>Improvements</h2>

* no re-compilation: focus on BT
* implement in OS (kernel)
::::
:::

## More Specific

::: {.container}
:::: {.col}
**Venkat's idea**

* re-compiled apps
* *kernel*
* compiler
* ISA HT
::::
:::: {.col}
**My idea**

* original apps
* kernel
* BT
* ISA HT
::::
:::: {.col}
<img src="./pictures/isa_ht_for_bt.svg" style="zoom: 200%;">
::::
:::

## guest ISA core

::: {.container}
:::: {.col}
<img src="./pictures/guest_isa_core.svg" style="zoom: 200%;">
::::
:::: {.col}
* SW BT: no legit problem
* KBT: inspired by KVM
  * Host/Guest seperate VA space
* uops: no PC mismatch problem
  * no indirect jump problem
* uops: designed for Host/Guest
  * e.g. Host/ARM uops
  * e.g. Host/x86 uops
::::
:::

## My plan

* uops: IR + graph algorithm
  * BT IR
  * ISA Semantics IR
* uArch: Gem5 + McPat
  * prove performance improvement
  * prove energy saving
* kernel: ISA-HT QEMU-sys
  * ISA-HT QEMU-sys replace Gem5

# My Works

Goal: A Methodology to generate uops

<h2>An analogue</h2>

| Linear Algebra          | Computer Science            |
|-------------------------|-----------------------------|
| Vector A vs Vector B    | Host ISA vs Guest ISA       |
| Common Base Vector      | Intermediate Representation |
| Distance                | Distance?                   |
| Linear Independent Base | minimal Cover?              |

## Choose IR

* BT IR
  * QEMU tcg
  * LLVM IR
* Semantics ISA IR

## Semantics ISA IR

* cakeml[1], ACL2, K[2], FuzzBall[3], sail\[4\][5], ...

<h3>Goal</h3>

* Model ISA in math rigorous language.
* Auto generate test-orcale tool.
* Compute allowed behaviours in test cases.
* Provide reference for HW/SW dev.

:::{style="zoom:40%;"}
* \[1\]: Kumar, Ramana et al. “CakeML: a verified implementation of ML.” Proceedings of the 41st ACM SIGPLAN-SIGACT (2014).
* \[2\]: Dasgupta, Sandeep et al. “A complete formal semantics of x86-64 user-level instruction set architecture.” Proceedings of the 40th ACM SIGPLAN (2019).
* \[3\]: https://github.com/bitblaze-fuzzball/fuzzball
* \[4\]: Gray, Kathryn E. et al. “An integrated concurrency and core-ISA architectural envelope definition, and test oracle, for IBM POWER multiprocessors.” 48th MICRO (2015): 635-646.
* \[5\]: Armstrong, Alasdair et al. “Detailed Models of Instruction Set Architectures : From Pseudocode to Formal Semantics.” (2018).
:::

## FuzzBall

Compilation

<img src="./pictures/multi2multi.svg" style="zoom: 150%;">

Parameterization

<img src="./pictures/para.svg" style="zoom: 150%;">

:::{style="zoom: 40%;"}
Wang, Wenwen et al. “Enhancing Cross-ISA DBT Through Automatically Learned Translation Rules.” 23rd ASPLOS (2018).
:::

## FuzzBall

<img src="./pictures/para.svg" style="zoom: 150%;">

FuzBall Symbolic Execution (Simplified Ver.)

```
r1_output  = r0 + r1 - 1
edx_output = eax + edx + (-1)
```

SMT Solver

```
∀ x,y ∈ int32
┌─r0 = eax = x
├─r1 = edx = y
└─r0 + r1 -1 = eax + edx + (-1)
```

## Sail

Focus on ISA concurrecny model

<img src="./pictures/2015.power_mp_sync_ctrl.svg" style="zoom:200%;">

## Summary

* Goal: A Methodology to generate uops
* Tool: IR
* Algorithm: Distance? Cover?

# Distance

| Linear Algebra          | Computer Science            |
|-------------------------|-----------------------------|
| Vector A vs Vector B    | Host ISA vs Guest ISA       |
| Common Base Vector      | Intermediate Representation |
| Distance                | Distance?                   |

:::{.fragment}
An Inst => several IRs => A Graph
:::

:::{.fragment}
Graph Distance[1]
:::

:::{.fragment style="zoom: 50%;"}
\[1\]: **Algo Intro**: Bengoetxea, Endika. “Inexact Graph Matching Using Estimation of Distribution Algorithms.” Doc Thesis (2002).
:::

## Extract Pattern from Graphs

* Once we have Distance,
  * Divide Graphs into groups.
* Once we have Distance,
  * Gradient descent.

```
get_a_uop_from_group:
    while (true)
        g = Gradient(uop, group)
        if (g < τ)
            yield uop
            break
        uop += ε * g
```

Unsupervised Learning: extract

:::{style="zoom: 45%;"}
\[1\]: Zhang, Quanshi et al. “Attributed Graph Mining and Matching: An Attempt to Define and Extract Soft Attributed Patterns.” CVPR (2014).
:::

## My Implementation

* ISA: aarch64 & x86-64
* IR: LLVM IR

::: {.container}
:::: {.col}
1. Remill[1]: an Inst => several LLVM IRs
2. LLVM Pass: several LLVM IRs => a Graph
3. networkx (python): graph algorithm
  * graph edit distance
  * aarch64:33 * x86-64:351 = 11582 pairs
::::
:::: {.col}
x64: ADD_GPR8_MEMb

<img src="./pictures/ISEL_ADD_GPR8_MEMb-gai.dot.svg" style="zoom:200%;">
::::
:::

:::{style="zoom: 50%;"}
\[1]: https://github.com/lifting-bits/remill
:::

## Graph Edit Distance

::: {.container}
:::: {.col}
aarch64: ADD_64_ADDSUB_EXT

<img src="./pictures/ISEL_ADD_64_ADDSUB_EXT-gai.dot.svg" style="zoom:100%;">
::::
:::: {.col}
x64: ADD_GPR8_MEMb

<img src="./pictures/ISEL_ADD_GPR8_MEMb-gai.dot.svg" style="zoom:100%;">
::::
:::

Add 2 nodes, 2 edges.

Naive_GED = 2 + 2 = 4

## Result

[S…L…O…W…]{.fragment style="zoom:200%;"}
[…]{.fragment style="zoom:200%;"}
[…]{.fragment style="zoom:200%;"}
[…🐢]{.fragment style="zoom:200%;"}

:::{.fragment}
* graph edit distance
* aarch64:33 * x86-64:351 = 11582 pairs
:::

:::{.fragment style="zoom:200%;"}
It takes a whole night!
:::

## Why

<h3>Definitely</h3>

* LLVM generate too much info
  * e.g. PUNPCKHBW MMXq MEMq: ~50 nodes
  <img src="./pictures/ISEL_PUNPCKHBW_MMXq_MEMq.O3.dot.svg" style="zoom:50%;">
* Graph Edit Distance too complex
  * N-node graph * N-node graph: time ~O(N!)

<h3>Maybe</h3>

* python is slow

# Cover

| Linear Algebra          | Computer Science            |
|-------------------------|-----------------------------|
| Vector A vs Vector B    | Host ISA vs Guest ISA       |
| Common Base Vector      | <span class="fragment strike" data-fragment-index="3">Intermediate Representation</span> <span class="fragment" data-fragment-index="3">Sub-Graphs</span> |
| Distance                | ~~Distance?~~               |
| Linear Independent Base | minimal Cover?              |

:::{.fragment data-fragment-index="1"}
An Inst => several IRs => A Graph
:::

:::{.fragment data-fragment-index="2"}
A Graph => All its Sub-Graphs
:::

:::{.fragment data-fragment-index="4"}
For all Insts, counting their Sub-Graphs freq.
:::

## More Specific

* Get all Sub-graphs of a Inst
* Count Sub-Graphs freq. for all Insts
* Use weighted (freq.) Sub-Graphs, to minial cover Insts

## My Implementation - 123

* ISA: aarch64 & x86-64
* IR: QEMU TCG
* Lang: CPP

1. asmjit[1]: enumerate Insts
2. QEMU-user single-step: an Inst => several TCGs
3. these TCGs => a Graph

:::{style="zoom: 50%;"}
\[1]: https://github.com/asmjit/asmjit.git
:::

## preprocess TCGs

::: {.container}
:::: {.col}
aarch64 Inst

```
2D48003A : setf16 w1
```

TCGs

```
mov_i32 tmp0,reg0
shl_i32 NF,tmp0,0x10
shl_i32 VF,tmp0,0xf
mov_i32 ZF,NF
xor_i32 VF,VF,NF
```
::::
:::: {.col}
Parameterization

* w1 => reg0

Not SSA

* tmp0: multiple values
::::
:::

## TCGs to a Graph

::: {.container}
:::: {.col}
aarch64 Inst

```
2D48003A : setf16 reg0
```

TCGs

```
mov_i32 tmp0,reg0
shl_i32 NF,tmp0,0x10
shl_i32 VF,tmp0,0xf
mov_i32 ZF,NF
xor_i32 VF,VF,NF
```
::::
:::: {.col}
<img src="./pictures/2D48003A.dot.svg" style="zoom:60%;">
::::
:::

## My Implementation - 456

4. this Graph => all Induced-Connected Sub-Graphs
  Induced: all edges connecting pairs of nodes are in Sub-Graph
5. count the freq. of these Sub-Graphs => map {freq, Sub-Graphs}
6. cover Insts with minial **weight** by using these Sub-Graphs
  naive_weight = freq

## Induced-Connected Sub-Graphs

::: {.container}
:::: {.col}
<img src="./pictures/2D48003A.dot.svg" style="zoom:60%;">
::::
:::: {.col}
enumerate Induced Connected Sub-Graphs by recursive algo. Time: ~O(2^n)

* nodes: 11
* compute_nodes: 5 (num of TCGs)
* Induced Sub-Graphs: 32 = 2^5
* Induced Connected Sub-Graphs: 22
::::
:::

## Count freq of Sub-Graphs

* Sub-Graphs => string => hash => hash table
* Num of Sub-Graphs
  * Inst ~ 5 nodes
  * Graph ~ 2^5 ~ 30 Sub-Graphs
  * ~700 aarch64 Insts
  * ~10^4 Sub-Graphs

## Result so far

:::{style="zoom:70%;"}
1. ☑ asmjit[1]: enumerate Insts
2. ☑ QEMU-user single-step: an Inst => several TCGs
3. ☑ these TCGs => a Graph
4. ☑ this Graph => all Induced-Connected Sub-Graphs
5. ☑ count the freq. of these Sub-Graphs => map {freq, Sub-Graphs}
6. ☐ cover Insts with minial **weight** by using these Sub-Graphs
:::

<h3>Insteresting Info</h3>

* Program run in several seconds
* 797 aarch64 basic Insts => 29315 Sub-Graphs
* most weighted Sub-Graph
```
shl_i64 =tmp1,tmp0,0x8
sar_i64 =tmp2,tmp1,0x8
and_i64 =tmp4,@01b4e86a93660d9f,tmp3;
```
